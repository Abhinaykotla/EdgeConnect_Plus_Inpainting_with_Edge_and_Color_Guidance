\section{Related Work}
\label{sec:related_work}

Early image inpainting methods relied on hand-crafted priors to propagate information from surrounding regions. Diffusion-based approaches, such as PDE-based diffusion (partial differential equation–based inpainting)~\cite{bertalmio2000image}, and exemplar-based techniques, like Criminisi et al's approach~\cite{criminisi2004region}, achieved reasonable results for small or texture-homogeneous holes, but struggled with semantically meaningful content and large missing regions.

The advent of deep learning enabled significant progress. Context Encoders~\cite{pathak2016context} were among the first to leverage encoder-decoder architectures with adversarial losses for inpainting, producing semantically plausible content but often yielding blurry results. Subsequent advances, such as Partial Convolutions~\cite{liu2018partial} and Gated Convolutions~\cite{yu2019free}, improved mask handling by modifying convolutional operations to respect missing regions. Attention-based mechanisms like DeepFill~\cite{yu2018generative} enabled long-range feature borrowing to improve visual continuity, while HiFill~\cite{yi2020contextual} offered efficient high-resolution inpainting. CoModGAN~\cite{zhao2021comodgan} further improved global consistency through feature-wise modulation of the generator network.

A parallel line of work explored the use of structural priors. PEN-Net~\cite{zeng2020learning} predicted edge maps to guide completion, and RFR-Inpainting~\cite{li2020recurrent} employed recursive reasoning to refine structural features. EdgeConnect~\cite{nazeri2019edgeconnect} formalized a two-stage approach in which an edge generation network guides the final image synthesis. However, these methods often ignore chromatic coherence, which can lead to unnatural color transitions or desaturation in completed regions.

More recently, transformer-based and diffusion-based models have evolved. ICT~\cite{wan2021image} introduced external memory mechanisms for capturing long-range dependencies, and DFI~\cite{lugmayr2022repaint} applied denoising diffusion probabilistic models for iterative image refinement. While powerful, such models tend to be computationally intensive and less interpretable, with limited control over fine-grained guidance.

Our work builds on EdgeConnect’s structure-first approach by introducing explicit chromatic guidance alongside structural priors. We incorporate a low-frequency blurred color map to provide coarse color consistency and fuse it with edge predictions in a unified framework. Unlike prior works that treat structure and texture separately or rely solely on implicit learning, EdgeConnect+ jointly models structural and chromatic cues to enhance perceptual realism in complex inpainting scenarios.

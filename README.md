
# EdgeConnect+: Adversarial Inpainting with Edge and Color Guidance

EdgeConnect+ is a deep learning-based image inpainting framework that enhances the original [EdgeConnect](https://arxiv.org/abs/1901.00212) model. This project integrates both **edge structure** and **color guidance** to produce perceptually realistic reconstructions of masked images.

---

## ğŸ§  Overview

The model is divided into a three-stage pipeline:

1. **Edge Generation (G1)**: Predicts edges in masked regions using grayscale input and binary masks.
2. **Color Map Generation**: Provides low-frequency chromatic information using Gaussian blur; future work includes using Partial Convolutions and Contextual Attention for improved color realism.
3. **Final Inpainting (G2)**: Uses a composite RGB input (edge, color, original image outside mask) + mask to synthesize realistic image completions.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config.py                  # Global configuration
â”œâ”€â”€ train.py                   # Main entry point
â”œâ”€â”€ dataloader_g1.py           # Dataloader for G1
â”œâ”€â”€ dataloader_g2.py           # Dataloader for G2
â”œâ”€â”€ g1_model.py                # Generator and Discriminator for G1
â”œâ”€â”€ g2_model.py                # Generator for G2
â”œâ”€â”€ loss_functions.py          # All loss definitions (L1, Adv, FM, Perceptual, Style)
â”œâ”€â”€ train_loops_g1.py          # Training loop for G1
â”œâ”€â”€ train_loops_g2.py          # Training loop for G2
â”œâ”€â”€ utils_dl.py                # Dataset utilities
â”œâ”€â”€ utils_g1.py                # Utilities for training G1 (saving, evaluation, etc.)
â”œâ”€â”€ utils_g2.py                # Utilities for training G2
â”œâ”€â”€ find_lr.py                 # Learning rate finder
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ results/                   # Output samples and evaluation plots
```

---

## ğŸ§ª Datasets

- **CelebA Dataset**: All images are center-cropped and resized to 256Ã—256.
- Irregular binary masks generated with â‰¥ 20% coverage.
- Masks applied during preprocessing to create white-hole inputs.
- Ground truth edges from Canny on original images.
- Input edges computed from masked image with mask-edges removed.

---

## ğŸ“ˆ Current Progress

| Stage | Status |
|-------|--------|
| G1 Edge Generator | âœ… Trained and evaluated |
| Color Map | âœ… Implemented |
| G2 Inpainting | ğŸš§ Training in progress |
| Loss Curves & Logs | âœ… Available |
| Evaluation Metrics | ğŸ”œ PSNR, SSIM, LPIPS, MAE |

---

## ğŸ§¾ Loss Functions

- `L1 Loss`: Structural fidelity
- `Adversarial Loss`: GAN realism (NS-GAN)
- `Feature Matching`: For discriminator stability
- `Perceptual Loss`: From VGG16
- `Style Loss`: Texture preservation via Gram matrices
- `Gradient Penalty`: For discriminator regularization

---

## ğŸ§ª Evaluation Metrics

Planned metrics to evaluate model output:
- **PSNR** (Higher is better)
- **SSIM** (Closer to 1 is better)
- **LPIPS** (Lower is better)
- **L1 Error** (Lower is better)

---

## ğŸš€ Training Setup

- Batch Size: 12
- Epochs: 100 (G1); G2 training ongoing
- Optimizer: Adam (lr=1e-4, weight_decay=5e-5)
- Mixed Precision + EMA
- Early Stopping: 5 epoch patience

---

## ğŸ“· Visual Results

You can find sample outputs in the `results/` directory, including:
- Edge maps generated by G1
- Masked input/output samples
- Loss trend plots

---

## ğŸ”­ Future Work

- Finish G2 model training and fine-tuning
- Replace Gaussian blur with learnable color propagation (Partial Convolutions, Contextual Attention)
- Expand to general-purpose datasets like **Places2**
- Integrate real-time inference pipeline

---

## ğŸ¤ Contributors

- **Abhinay Kotla** â€” [@abhinaykotla](https://github.com/Abhinaykotla)  
- **Sanjana Ravi Prakash** â€” [@sanjanarp](https://github.com/sanjanarp)

---

## ğŸ“„ License

This repository is shared for educational and research purposes.

---

## ğŸ“¬ Acknowledgements

- [EdgeConnect (Nazeri et al.)](https://arxiv.org/abs/1901.00212)
- [CelebA Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)
- [PartialConv](https://arxiv.org/abs/1804.07723)
- [Contextual Attention](https://arxiv.org/abs/1801.07892)

---
